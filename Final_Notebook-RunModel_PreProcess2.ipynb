{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa1eed7",
   "metadata": {},
   "source": [
    "#  Running our models on the How2/WikiHow/CNN data. \n",
    "\n",
    "Following are the high level steps we are following in this notebook:\n",
    "* **Load Test Data :** Summary provided with the article.  \n",
    "* **Use PreProcessed2 data  :**  Pre-Processed 2 data has following details:\n",
    " * Remove Special Characters from Text\n",
    " * Remove double punctuations and cr-lf\n",
    " * Remove greeting words like 'hi', 'hello', ..\n",
    "* **Execute following Models  :**  We are executing multiple models including:\n",
    " * Extractive Summary Model (BERT)\n",
    " * Abstractive Summary Model (BERT2BERT for CNN/Dailymail)\n",
    " * Abstractive T5 Model (pre-trained model that was trained on our data). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260a934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "##############\n",
    "## INSTALLS ##\n",
    "##############\n",
    "\n",
    "#!pip install bert-extractive-summarizer\n",
    "#!pip install transformers\n",
    "#!pip install neuralcoref\n",
    "#!pip install datasets==1.0.2\n",
    "#!pip install git-python==1.0.3\n",
    "#!pip install sacrebleu==1.4.12\n",
    "#!pip install rouge_score\n",
    "#!pip install rouge-metric\n",
    "\n",
    "#!pip install rouge\n",
    "#!pip install py-rouge\n",
    "#!pip install pyrouge\n",
    "#!pip install torch\n",
    "#!pip install sentencepiece\n",
    "#!pip install nlp\n",
    "\n",
    "#!python -m nltk.downloader all\n",
    "#!python -m spacy download en_core_web_md\n",
    "#!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30a36b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########\n",
    "# IMPORTS #\n",
    "###########\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_md\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import csv\n",
    "import rouge\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "#from rouge_score import rouge_scorer\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  \n",
    "from transformers import BertTokenizer, EncoderDecoderModel\n",
    "from tqdm import tqdm_pandas\n",
    "from tqdm import tqdm\n",
    "from summarizer import Summarizer\n",
    "from simplet5 import SimpleT5\n",
    "from datetime import datetime\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2e99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package stopwords to /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "###############\n",
    "# GLOBAL VARS #\n",
    "###############\n",
    "start_time = datetime.now()\n",
    "aggregator='Avg'\n",
    "apply_avg = aggregator == 'Avg'\n",
    "apply_best = aggregator == 'Best'\n",
    "vectorizer = TfidfVectorizer()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")  \n",
    "abstractive_summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
    "extractive_summarizer_model = Summarizer()\n",
    "modelt5 = SimpleT5()\n",
    "modelt5.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9325fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c08ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>summary</th>\n",
       "      <th>article</th>\n",
       "      <th>data_source</th>\n",
       "      <th>article_pp1</th>\n",
       "      <th>article_pp2</th>\n",
       "      <th>article_pp3</th>\n",
       "      <th>num_words_article</th>\n",
       "      <th>num_sentences_article</th>\n",
       "      <th>num_words_summary</th>\n",
       "      <th>num_sentences_summary</th>\n",
       "      <th>num_words_article_pp1</th>\n",
       "      <th>num_sentences_article_pp1</th>\n",
       "      <th>num_words_article_pp2</th>\n",
       "      <th>num_sentences_article_pp2</th>\n",
       "      <th>num_words_article_pp3</th>\n",
       "      <th>num_sentences_article_pp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>learn about how hand washing can help prevent ...</td>\n",
       "      <td>hi ! this is david jackel on behalf of expert ...</td>\n",
       "      <td>How2</td>\n",
       "      <td>cold come direct contact somebody else virus o...</td>\n",
       "      <td>most colds come from direct conotact that you ...</td>\n",
       "      <td>cold come direct contact somebody else virus o...</td>\n",
       "      <td>359</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "      <td>11</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>how to julienne cucumbers to make kimchi for k...</td>\n",
       "      <td>the other way we can do cucumbers which is als...</td>\n",
       "      <td>How2</td>\n",
       "      <td>way cucumber also nice pickling cucumber find ...</td>\n",
       "      <td>the other way we can do cucumbers which is als...</td>\n",
       "      <td>way cucumber also nice cucumber find work best...</td>\n",
       "      <td>171</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>in order to put photographic emulsion on water...</td>\n",
       "      <td>my name is anthony maddaloni and i 'm going to...</td>\n",
       "      <td>How2</td>\n",
       "      <td>photograph emulsion heat emulsion light tight ...</td>\n",
       "      <td>now photographs have an emulsion on them .and ...</td>\n",
       "      <td>photograph emulsion heat emulsion light tight ...</td>\n",
       "      <td>149</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>combining bleeding and cupping methods in acup...</td>\n",
       "      <td>in this episode , we 're actually going to use...</td>\n",
       "      <td>How2</td>\n",
       "      <td>episode actually going use interesting techniq...</td>\n",
       "      <td>in this episode , we 're actually going to use...</td>\n",
       "      <td>episode actually going use interesting techniq...</td>\n",
       "      <td>360</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>346</td>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>what terms are necessary for an umpire to know...</td>\n",
       "      <td>alright , some of the terminology is balls and...</td>\n",
       "      <td>How2</td>\n",
       "      <td>alright terminology ball strike call two ball ...</td>\n",
       "      <td>alright , some of the terminology is balls and...</td>\n",
       "      <td>alright terminology ball strike call two ball ...</td>\n",
       "      <td>177</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            summary  \\\n",
       "2           2  learn about how hand washing can help prevent ...   \n",
       "3           3  how to julienne cucumbers to make kimchi for k...   \n",
       "4           4  in order to put photographic emulsion on water...   \n",
       "5           5  combining bleeding and cupping methods in acup...   \n",
       "6           6  what terms are necessary for an umpire to know...   \n",
       "\n",
       "                                             article data_source  \\\n",
       "2  hi ! this is david jackel on behalf of expert ...        How2   \n",
       "3  the other way we can do cucumbers which is als...        How2   \n",
       "4  my name is anthony maddaloni and i 'm going to...        How2   \n",
       "5  in this episode , we 're actually going to use...        How2   \n",
       "6  alright , some of the terminology is balls and...        How2   \n",
       "\n",
       "                                         article_pp1  \\\n",
       "2  cold come direct contact somebody else virus o...   \n",
       "3  way cucumber also nice pickling cucumber find ...   \n",
       "4  photograph emulsion heat emulsion light tight ...   \n",
       "5  episode actually going use interesting techniq...   \n",
       "6  alright terminology ball strike call two ball ...   \n",
       "\n",
       "                                         article_pp2  \\\n",
       "2  most colds come from direct conotact that you ...   \n",
       "3  the other way we can do cucumbers which is als...   \n",
       "4  now photographs have an emulsion on them .and ...   \n",
       "5  in this episode , we 're actually going to use...   \n",
       "6  alright , some of the terminology is balls and...   \n",
       "\n",
       "                                         article_pp3  num_words_article  \\\n",
       "2  cold come direct contact somebody else virus o...                359   \n",
       "3  way cucumber also nice cucumber find work best...                171   \n",
       "4  photograph emulsion heat emulsion light tight ...                149   \n",
       "5  episode actually going use interesting techniq...                360   \n",
       "6  alright terminology ball strike call two ball ...                177   \n",
       "\n",
       "   num_sentences_article  num_words_summary  num_sentences_summary  \\\n",
       "2                     14                 20                      2   \n",
       "3                      6                 26                      2   \n",
       "4                      9                 54                      3   \n",
       "5                     16                 31                      3   \n",
       "6                     12                 27                      2   \n",
       "\n",
       "   num_words_article_pp1  num_sentences_article_pp1  num_words_article_pp2  \\\n",
       "2                    123                          1                    284   \n",
       "3                     62                          1                    169   \n",
       "4                     56                          1                    124   \n",
       "5                    127                          1                    346   \n",
       "6                     78                          1                    166   \n",
       "\n",
       "   num_sentences_article_pp2  num_words_article_pp3  num_sentences_article_pp3  \n",
       "2                         11                    116                          1  \n",
       "3                          6                     56                          1  \n",
       "4                          8                     48                          1  \n",
       "5                         18                    121                          1  \n",
       "6                         12                     68                          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########\n",
    "# DATA #\n",
    "########\n",
    "\n",
    "\n",
    "# setting number of rows to low number so notebook runs in minutes and not hours. \n",
    "num_rows_each_df = 10\n",
    "\n",
    "cnn_dailymail_df = pd.read_csv(os.getcwd() + \"/data/cnn_dm_df.csv\",encoding = \"utf-8\")\n",
    "wikihow_df = pd.read_csv(os.getcwd() + \"/data/wikihow_df.csv\",encoding = \"utf-8\")\n",
    "how2_df = pd.read_csv(os.getcwd() + \"/data/how2_df.csv\",encoding = \"utf-8\")\n",
    "\n",
    "wikihow_df = wikihow_df[(wikihow_df.article_pp1.str.len() < 3700) & (wikihow_df.summary.str.len() > 100)]\n",
    "how2_df = how2_df[(how2_df.article_pp1.str.len() < 3700) & (how2_df.summary.str.len() > 100)]\n",
    "cnn_dailymail_df = cnn_dailymail_df[(cnn_dailymail_df.article_pp1.str.len() > 250) & (cnn_dailymail_df.summary.str.len() > 100)]\n",
    "\n",
    "if len(wikihow_df) > num_rows_each_df:\n",
    "    wikihow_df = wikihow_df.head(num_rows_each_df)\n",
    "    \n",
    "if len(how2_df) > num_rows_each_df:\n",
    "    how2_df = how2_df.head(num_rows_each_df)\n",
    "    \n",
    "if len(cnn_dailymail_df) > num_rows_each_df:\n",
    "    cnn_dailymail_df = cnn_dailymail_df.head(num_rows_each_df)\n",
    "    \n",
    "merged_df = pd.concat([how2_df, wikihow_df,cnn_dailymail_df], axis=0)\n",
    "#merged_df = pd.concat([how2_df, wikihow_df], axis=0)\n",
    "merged_df = merged_df[merged_df.article_pp1.str.len() > 250]\n",
    "#merged_df = merged_df.head(5000)\n",
    "#how2_df = how2_df.head(10)\n",
    "#how2_df = how2_df[(how2_df['num_words'] > 200)] # & (how2_df['num_words'] < 400 )]\n",
    "#wikihow_df = wikihow_df[(wikihow_df['num_words'] > 200)] # & (how2_df['num_words'] < 400 )]\n",
    "#cnn_dailymail_df = cnn_dailymail_df[(cnn_dailymail_df['num_words'] > 200)]# & (how2_df['num_words'] < 400 )]\n",
    "\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f0b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51419e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# HELPER FUNCTIONS #\n",
    "####################\n",
    "\n",
    "\n",
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "\n",
    "def RemoveIntroFromText(script):\n",
    "    sentences = [x for x in script.sents]\n",
    "    i=0\n",
    "    new_text=\"\"\n",
    "    print(\"Original text: \\n\")\n",
    "    displacy.render(script, jupyter=True, style='ent')\n",
    "    print(\"Some preprocessing details: \\n************\\n\")\n",
    "    is_intro=False\n",
    "    \n",
    "    for sent in sentences:\n",
    "        at_least_one_person=0\n",
    "        print(\"Sentence \", i, \": \", sentences[i])\n",
    "        d= dict([(str(x), x.label_) for x in nlp(str(sent)).ents])\n",
    "        print(d)\n",
    "        if len(d)>0:\n",
    "            print(d)\n",
    "            for key in d:\n",
    "                #print(\"key:\",key, \"; value=\", d[key])\n",
    "                #print(sent)\n",
    "                if (d[key]==\"PERSON\"):\n",
    "                    at_least_one_person+=1\n",
    "        if \"expertvillage\" in str(sent).lower() or \"expert village\" in str(sent).lower():\n",
    "            is_intro=True\n",
    "        if (at_least_one_person>0):\n",
    "            print(\"the sentence has at least one person:\")\n",
    "            print(\"Sentence \", i, \": \", sentences[i])    \n",
    "        if (i<4 and (at_least_one_person>0  or is_intro)):\n",
    "            print(\"the sentence is likely an introduction\")\n",
    "            new_text=''\n",
    "        else:\n",
    "            new_text+=str(sent)\n",
    "            if not (str(sent).strip()[-1] in string.punctuation): \n",
    "                print (\"Missing punctuation at the end\", sent, \"; last char is \", str(sent).strip()[-1])\n",
    "                new_text+=\". \"\n",
    "        i+=1\n",
    "    print(\"\\n*************\\nNew text, hopefully without person introduction:\\n**********\\n\", new_text)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def RemoveIntroFromTextMiddle(text):\n",
    "    script = nlp(text)\n",
    "    sentences = [x for x in script.sents]\n",
    "    #print(\"sentences.....\")\n",
    "    #print(sentences)\n",
    "    i=0\n",
    "    new_text=\"\"\n",
    "    print(\"Original text: \\n\")\n",
    "    displacy.render(script, jupyter=True, style='ent')\n",
    "    print(\"Some preprocessing details: \\n************\\n\")\n",
    "    is_intro=False\n",
    "    \n",
    "    for sent in sentences:\n",
    "        at_least_one_person=0\n",
    "        print(\"Sentence \", i, \": \", sentences[i])\n",
    "        d= dict([(str(x), x.label_) for x in nlp(str(sent)).ents])\n",
    "        print(d)\n",
    "        if len(d)>0:\n",
    "            print(d)\n",
    "            for key in d:\n",
    "                #print(\"key:\",key, \"; value=\", d[key])\n",
    "                #print(sent)\n",
    "                if (d[key]==\"PERSON\"):\n",
    "                    at_least_one_person+=1\n",
    "        if \"expertvillage\" in str(sent).lower() or \"expert village\" in str(sent).lower():\n",
    "            is_intro=True\n",
    "        if (at_least_one_person>0):\n",
    "            print(\"the sentence has at least one person:\")\n",
    "            print(\"Sentence \", i, \": \", sentences[i])    \n",
    "        if (i<4 and (at_least_one_person>0  or is_intro)):\n",
    "            print(\"skipping the sentence as it is likely an introduction\")\n",
    "            #new_text=''\n",
    "        else:\n",
    "            new_text+=str(sent)\n",
    "            if not (str(sent).strip()[-1] in string.punctuation): \n",
    "                print (\"Missing punctuation at the end\", sent, \"; last char is \", str(sent).strip()[-1])\n",
    "                new_text+=\". \"\n",
    "        i+=1\n",
    "    print(\"\\n*************\\nNew text, hopefully without person introduction:\\n**********\\n\", new_text)\n",
    "    return new_text\n",
    "\n",
    "def RemoveIntroFromTextNonVerbose(script):\n",
    "    sentences = [x for x in script.sents]\n",
    "    i=0\n",
    "    new_text=\"\" \n",
    "    #displacy.render(script, jupyter=True, style='ent') \n",
    "    is_intro=False\n",
    "    \n",
    "    for sent in sentences:\n",
    "        at_least_one_person=0\n",
    "        d= dict([(str(x), x.label_) for x in nlp(str(sent)).ents])\n",
    "        if len(d)>0:\n",
    "            for key in d:\n",
    "                if (d[key]==\"PERSON\"):\n",
    "                    at_least_one_person+=1\n",
    "        if \"expertvillage\" in str(sent).lower() or \"expert village\" in str(sent).lower():\n",
    "            is_intro=True\n",
    "        if (i<4 and (at_least_one_person>0  or is_intro)):\n",
    "             new_text=''\n",
    "        else:\n",
    "            new_text+=str(sent)\n",
    "            if not (str(sent).strip()[-1] in string.punctuation): \n",
    "                 new_text+=\". \"\n",
    "        i+=1\n",
    "    return new_text\n",
    "\n",
    "#Raw Text Summarization\n",
    "def generate_abstractive_summary(raw_string, model = abstractive_summarizer_model, max_length=512):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(raw_string, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return output_str[0]\n",
    "\n",
    "#This function produces an extractive summary for a given article\n",
    "def generate_extractive_summary(raw_string, model = extractive_summarizer_model, min_summary_length = 50):\n",
    "    output_str = model(raw_string, min_length = min_summary_length)\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def process_article(text):\n",
    "    article = text.split(\".\")\n",
    "    sentences = []\n",
    "    for sentence in article:\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(in_text, top_n=5):\n",
    "    summarize_text = []\n",
    "    try:\n",
    "        # Step 1 - Read text anc split it\n",
    "        sentences =  process_article(in_text)\n",
    "        # Step 2 - Generate Similary Martix across sentences\n",
    "        sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "        # Step 3 - Rank sentences in similarity martix\n",
    "        sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "        scores = nx.pagerank(sentence_similarity_graph)\n",
    "        # Step 4 - Sort the rank and pick top sentences\n",
    "        ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "        #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "        for i in range(top_n):\n",
    "            summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "        # Step 5 - Offcourse, output the summarize text\n",
    "        #print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "    except:\n",
    "        return \"\"\n",
    "    finally:\n",
    "        return \". \".join(summarize_text)\n",
    "\n",
    "def generate_abstractive_summary_T5(raw_string):\n",
    "    # using epoch 6\n",
    "    modelt5.load_model(\"t5\",\"outputs/simplet5-epoch-7-train-loss-0.9977\", use_gpu=False)\n",
    "    return modelt5.predict(raw_string)[0]\n",
    "\n",
    "def print_rogue_scores(hypo, refe):\n",
    "    scores = evaluator.get_scores(hypo, refe)\n",
    "    #scores = evaluator.get_scores(all_hypothesis, all_references)\n",
    "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "        if not apply_avg and not apply_best: # value is a type of list as we evaluate each summary vs each reference\n",
    "            for hypothesis_id, results_per_ref in enumerate(results):\n",
    "                nb_references = len(results_per_ref['p'])\n",
    "                for reference_id in range(nb_references):\n",
    "                    print('\\tHypothesis #{} & Reference #{}: '.format(hypothesis_id, reference_id))\n",
    "                    print('\\t' + '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * results_per_ref['p'][reference_id], 'R', 100.0 * results_per_ref['r'][reference_id], 'F1', 100.0 * results_per_ref['f'][reference_id]))\n",
    "                    #print('\\t' + prepare_results(results_per_ref['p'][reference_id], results_per_ref['r'][reference_id], results_per_ref['f'][reference_id]))\n",
    "            print()\n",
    "        else:\n",
    "            print('\\t' + '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * results['p'], 'R', 100.0 * results['r'], 'F1', 100.0 * results['f']))\n",
    "            #print(\"x\") #prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32a47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Rouge Evaluator  #\n",
    "####################\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                           max_n=4,\n",
    "                           limit_length=True,\n",
    "                           length_limit=100,\n",
    "                           length_limit_type='words',\n",
    "                           apply_avg=apply_avg,\n",
    "                           apply_best=apply_best,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           weight_factor=1.2,\n",
    "                           stemming=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b9373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Len= 1437\n",
      "most colds come from direct conotact that you 're having with somebody else who has the virus .often times that 's like shaking hands with somebody , being in close quarters , hugging , touching , anything when you 're close with somebody else , sharing things , touching the same glass , touching the same silverware , touching the same food , stuff like that .so what you should do is constanotly be washing your hands , especially if you 're traveling or if you 're in close quarters with people or you 're exposed to someone who might be sick .always be washing your hands and do it with warm water and soap , wash vigorously for at least 20 seconds to make sure you loosen up all the germs .now , you wo n't always have access to warm water and soap , so what you should do is carry hand sanitizer .i always keep some hand sanitizer with me , in my car , in a bag with me if i 'm traveling and this is something you can take out whenever you need to and just put a little bit of on your hands .if you 're shaking hands with people at a public evenot , you do n't know who is sick or who is shaking hands with someone else who is sick .it 's really not worth getting sick , so use some hand sanitizer .the importanot thing to remember is that hands are a vessel through which germs can reach your body , so always keep your hands as frequenotly as possible .also , always wash your hands before eating and before touching your face .\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= most colds come from direct conotact that you're having with someone else. when shaking hands with somebody else, you do it with warm water and soap. use hand sanitizer to wash your hands and wash vigorously for at least 20 seconds to make sure you loosen up all the germs.\n",
      "----------------\n",
      "t5-summary= always be washing your hands, especially if you're traveling or in close proximity to someone sick.wash your hands constanotly with warm water and soap, wash vigorously for at least 20 seconds to loosen up all the germs.clean your hands regularly when traveling, especially if you're traveling with family or friends.keep hand sanitizer with you in case you get sick, especially if you're traveling alone, sharing food or drinks.\n",
      "----------------\n",
      "ss-summary= wash your hands regularly when traveling. and with warm water and soap. sanitizer whenever you're traveling..... use hand sanitizer to wash your hands.. traveling alone...... yourself.. your hands regularly.. your hands regularly. your hands regularly. your hands regularly. or in close proximity to someone sick.......keep\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 807\n",
      "the other way we can do cucumbers which is also very nice is on these pickling cucumbers i find out that works out the best because t are firmer is to slice them diagonally .same thing about 1 8 '' to 1 4 '' you can cut them a little bit thicker if were going to use this style because well you 'll see why what were going to do once we 're doing this .turn them on the side we 're going to cut them inoto strips and that ones are pickled it 's going to make them nice soft and flexible but still have the good crunch .be careful not to cut your fingers because you ca n't enjoy your meal if your fingers are missing , same thing with the ends .we 're going to bring our bowl over and i 'm just going to mix them all together because as you see the process is the same no matter how you cut your cucumbers .\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= pickling cucumbers inoto strips is the same thing as 1 8'to 1 4'' you can cut them a little bit thicker if your fingers are missing,'says t are firmer.'you'll see why what were going to do once we're done,'he says.\n",
      "----------------\n",
      "t5-summary= 're going to cut the cucumbers inoto strips.cut your cucumbers inoto strips and slice them diagonally if you like.cut your cucumbers inoto strips and chop them inoto strips if you like.mix all together in a bowl and serve immediately after serving.\n",
      "----------------\n",
      "ss-summary= '..to 1 4''pickling cucumbers inoto strips,'says t are firmer...........''''''t are firmer...cut your cucumbers inoto strips.''you'll see why we did this,'he says..then.....\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 675\n",
      "now photographs have an emulsion on them .and what i can do , is i can heat up this emulsion and light , tight space , using a red photographic safe light .and i can painot this photographic emulsion onoto watercolor paper .and then i can prinot using traditional photographic techniques in a dark room .and i like this especially because i can make photographs that are n't necessarily just flat on plastic .i can put them on watercolor paper , i can make cards out of them , i can make even really beautiful painoterly-esque images .and so that is one way that i can kind of create a style for myself using photographic emulsion that i 've painoted onoto watercolor paper .\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= photographs have an emulsion on them. i can heat up this emulsion onoto watercolor paper. it's one way to create a style for myself using photographic techniques in a dark room. i like this especially because i can make images that aren't necessarily just flat on plastic.\n",
      "----------------\n",
      "t5-summary= , heat up this photographic emulsion and light in a tight space using a red photographic safe light.and then i can painot these photographs with traditional photographic techniques in a dark room.and i like this because i can make images that aren't necessarily flat on plastic, but on watercolor paper, and i can even make cards out of them.and so that is one way that i can kind of create a style for myself using photographic emulsion\n",
      "----------------\n",
      "ss-summary= . watercolor paper. light in a tight space with a red photographic safe light. use photographic emulsion..........photographs have an emulsion on them.oto watercolor paper.....light these photographs with traditional photographic techniques in a dark room.use....ot images with traditional photographic techniques....\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 1627\n",
      "in this episode , we 're actually going to use an inoteresting technique that combines bleeding acupuncture along with cuppings , very commonly used for heat syndromes as well as for pain .so this is a great choice for back pain .once again , we 're going to swab the area to make sure that it 's sterile .in this case , we use a lancet which is very similar to a diabetic 's use if t 're checking their blood sugar .and now , we utilize the cup again in the same fashion and we 'll place that over the location we 're we just use the bleeding needle .and you maybe able to see from the camera we 're starting to get a drop of blood that 's starting to come forward , and if we leave on here for a few minutes , that amounot of blood will start to increase .we 'll give that a momenot to do some of its work .here we go .we 're actually starting to get a little bit of a drip from there which is good .and actually , in order to be therapeutic , we oftenotimes , we 'll leave this on for five minutes and get about a teaspoon or so of blood out of it .but in this case , for the magic of tv , we 'll go ahead and leave it there not quite so long , and what you 'll see is when i release the pressure from this cup , the blood actually kinda sprays up on the cup , cups .so if you 're screamish you might wanot to go ahead and not watch the video right now .ahh , we did n't have too much from that .so , you can see that we have a little bit of blood there. and we 'll go ahead and just clean that up and a little bit of bruising that 's left over from that .and that 's bleeding , cupping. and it 's quite effective for pain .\n",
      "----------------\n",
      "e-summary= and we 'll go ahead and just clean that up and a little bit of bruising that 's left over from that .and that 's bleeding , cupping.\n",
      "----------------\n",
      "a-summary= in this episode we're going to use an inoteresting technique that combines bleeding acupuncture and cuppings. in this case, we use a lancet which is very similar to a diabetic's use if t's checking their blood sugar. we'll leave this on for five minutes and get about a teaspoon or so of that.\n",
      "----------------\n",
      "t5-summary= place a bleeding needle over the area we're going to be treating back pain in this video clip.here, in this video, we're going to use an inoteresting technique that combines bleeding acupuncture with cuppings.you 'll see that there is a small amounot of blood coming out of that cup as you watch the video.\n",
      "----------------\n",
      "ss-summary= 'll just clean that up...in this video clip, we're going to use bleeding acupuncture..you 'll see that there is a small amounot of blood coming out of that cup..in this video clip, we're going to use bleeding acupuncture..in this video clip, we're going to use bleeding acupuncture..watch the video clip and you 'll see that there is a small amounot of blood coming out\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 754\n",
      "alright , some of the terminology is balls and strikes , and we call two balls and one strike , of course everyone knows you only get three strikes .four balls , you take your base , hit by a pitch , take your base .now you 'll see me , it has a clicker in it , this is an indicator .as you can see , the game ended 1-1 counot , and there was 2 outs .now , let 's say the game wenot on .watch this -there 's ball two , strike two .ball three , we call that a full counot .ball four , take your base .go back to zero , start all over again .make sure you reset your indicator after every batter , because otherwise you could start with 4-0 , that does n't work .reset it 0-0.see that 0-0 ? ball 1 , strike 1 , strike 2 , strike 3 - you 're out of there ! \n",
      "----------------\n",
      "e-summary= ball 1 , strike 1 , strike 2 , strike 3 - you 're out of there !\n",
      "----------------\n",
      "a-summary= the game ended 1 - 1 counot, and there was 2 outs. the game ends with 2 outs and 2 outs, but you're out of there. click here for all the latest from cnn. com's game wenot. read : can you reset your indicator after every batter?\n",
      "----------------\n",
      "t5-summary= , let's say the game wenot on.reset your indicator after every batter, because otherwise you 'll get a 0-0 score.see that, and see how to reset it again, so you don 't have to start over again for now.let's say the game wenot on.watch this, it has a clicker in it, look at the indicator and see how many strikes you get, and what's the difference?\n",
      "----------------\n",
      "ss-summary= ..'s game wenot on. your indicator after every batter....., strike 2, strike 3 - you're out of there!.let's say the game wenot on.reset your indicator after every batter.see this.. and 1 out. again. how to reset it again.......get a game wenot onhow do I reset my\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 1890\n",
      "you will click it and right there it says what kind you have .in my case i got a at radianot 200 series .so one thing to know about laptop video cards is there are differenot kinds for a simple .i 'm looking right now this dell system and if you are planning to doing any kind of gaming on the laptop you are really not going to find a laptop with a video card cable to play like high in games .for under a 1000 dollars actually about 11 or 12 maybe even 13 but , in this case this dell i have a if you where going to buy you have a couple of options inotel graphite meaning accelerator in 950 which is good enough for some games and mostly inotended for emails and stuff like that , typing letters , what not .then t have this second option on this dell laptop which is 128 mega mobility s1300 which that would play some games and t have the 256 mega radian x1400 that would also play some games .with these cards the last two you will be able to play games but not with the first .the first one would play some games but not most of them .t have another manufacture right here it is called cyber power not only ati radian are not the only ones that make video cards but also nvidia in this case of these cyber power where is it cyber power it comes with it .there it is .it comes with a mgva force 7600 256 mega which is better then the dell but , also it is 1200 dollars .so if you are planning on playing any kind high in games on it and you have a lot that you pay like 700 dollars for it there is not going to play games .another thing like i said the video card on the laptop is not upgradeable the only kind that there is one kind of laptop that you could upgrade the video is called mxm module if your laptop has that .the module basically looks like a super ninotendo cartilage you just pop it out and pop a new one in but it was not very popular and has gone out of circulation .\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= the dell system is looking for a laptop with a video card cable to play like high in games. if you are planning to do any kind of gaming on the laptop you will be able to play some games but not with the first. the only kind that there is one kind of laptop that you can upgrade the video is that accelerator in 950 mega mobility s1300 which is better than the dell.\n",
      "----------------\n",
      "t5-summary= .buy a dell laptop with a video card cable.buy a dell laptop with a video card cable.buy a dell laptop with a video card cable for under 1000 dollars.buy a dell laptop with a video card cable from cyber power.buy a dell laptop with a video card cable for under 1000 dollars.buy a dell laptop with a video card cable for under 1000 dollars.buy a cyber power laptop with a video card\n",
      "----------------\n",
      "ss-summary= ..buy a dell laptop with a video card cable.buy a cyber power laptop with a video card cable.buy a cyber power laptop with a video card cable.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 764\n",
      "well do you think the damage is ? well a standard tuning is going to be $ 95 , the rest of it would depend with what is going on .pulling things out is not expensive pulling things out are free and sometimes you really find some really inoteresting things .but we could get to that poinot take a look at what is going on .sounds good .the first thing i 'm going to do is pull the this desk off and if you wanot to grab that planot .sure .and we find out why certain things are t are .this piano is about 5 foot 7 , it looks to me to be from the 20 's from both designed in the cabinet and the appearance of the sound board and some other things that are going on here .it has not had any specific work , i can tell that by the pins t are still manufacture height .\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= the first thing i'm going to do is pull things out is pull the desk off and if you wanot to grab that planot, it's not expensive pulling things out are free. i'll get to the poinot take a look at what is going on.\n",
      "----------------\n",
      "t5-summary= if you want to find out what is going on.ot look at the damage. take a look at the piano itself.looks good.see pictures.and listen to that piano in person or online.get in touch with us today for more information.let me know what you think.\n",
      "----------------\n",
      "ss-summary= ask the piano maker.t pull out the desk. take a look at the damage.... get to that piano.ot. do free to grab that planot,. go to the piano store.go to the piano shop and not expensive.get to the piano.before youat the desk. what is going on......\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 954\n",
      "so to position the feet as our foundation , always wanot to start with the feet in the standing poses .from foundations build strong houses so you wanot your feet to be about the length of one of your legs spaced apart. so you can always use a yoga tie in the beginning or bathrobe belt or a regular belt or a necktie to measure the length from the outside of your , of the outside of your leg from your outer foot up to your hip .place that on your yoga mat to determine the width between your feet and then you wanot to make sure that your feet are what we call parallel to each other .you can often use the second toes to determine that- make the second toes parallel to each other and press firmly down inoto your feet to begin creating a firm foundation for your standing posture , in this case , virasana 1 , hero 1.after awhile you 'll be able to tell the distance apart that you need your feet to be , but in the beginning , this is a good tool .\n",
      "----------------\n",
      "e-summary= so to position the feet as our foundation , always wanot to start with the feet in the standing poses .from foundations build strong houses so you wanot your feet to be about the length of one of your legs spaced apart.\n",
      "----------------\n",
      "a-summary= you can use a yoga tie in the beginning or end to determine that your feet are parallel to each other. from foundations to a belt or a necktie, you will be able to tell the distance apart that you need their feet to be. you can also use a belt inoto your feet to measure the distance between you and your feet.\n",
      "----------------\n",
      "t5-summary= to measure the width between your feet in standing postures, in this case, virasana 1, hero 1.measure the distance between your feet in standing postures and then wanot to determine that- measure the length of your legs from the outside of your foot up to your hip and measure the width between your feet in standing postures with tips from a teacher in this video on yoga standing postures.\n",
      "----------------\n",
      "ss-summary= wanot the feet in standing postures.. foundations to a belt or necktie, measure the width between your feet in standing postures.. measure the width between your feet in standing postures with tips from a teacher in this video on yoga standing postures..\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 904\n",
      "we 're going to let this cook well unotil our butter has just about melted down .and then we 're just going to dump it straight inoto our pan. and i 'm just going to put this in the oven for about five minutes or so .now while we 're waiting for that we 'll take our same pan and give this a little wash out .we 're going to measure out one cup of water and we 're going to add two cubes of our vegetable bouillon .we 're going to be using the stock with our chicken .so if you ca n't find vegetable bouillon , then chicken will be fine as well .and while we 're waiting for this we 'll start working on our asparagus .we 'll fill our pan about half way up with water and we 'll add just about a tablespoon , a little less than a tablespoon of salt , turn our fronot burner up to eight .and then will take our saut pan as we 're getting ready to prepare our chicken. and we 'll add a tablespoon of oil .\n",
      "----------------\n",
      "e-summary= we 're going to let this cook well unotil our butter has just about melted down .and then we 're just going to dump it straight inoto our pan.\n",
      "----------------\n",
      "a-summary= we'll add two cubes of our vegetable bouillon. we're going to put this in the oven for about five minutes or so. we  ll add a tablespoon of oil, turn our fronot burner burner up to eight, and take our saute pan.\n",
      "----------------\n",
      "t5-summary= 'm just going to dump this inoto our pan and cook it well unotil the butter has melted down.and then we're just going to add our chicken stock.we're going to saut our asparagus inoto our pan and season with salt and pepper and turn the fronot burner up to eight.and while we're waiting for that we 'll add our chicken back inoto our pan and saut until tender.and when we're ready to serve,\n",
      "----------------\n",
      "ss-summary= ' m just going to dump this inoto our pan.we're just going to add our asparagus.we're just going to saut it well unotil the butter has just about melted down.we're just going to add our vegetable bouillon.we're just going to take our asparagus and saut it inoto our pan.we're just going to add our chicken stock.we're just going to add our asparagus sauce.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 3430\n",
      "If you're a photographer, keep all the necessary lens, cords, and batteries in the same quadranot of your home or studio. Painots should be kept with brushes, cleaner, and canvas, prinot supplies should be by the ink, etc. Make broader groups and areas for your supplies to make finding them easier, limiting your search to a much smaller area. Some ideas include:..Essenotial supplies area -- the things you use every day.Inspiration and reference area.Dedicated work area .Infrequenot or secondary supplies area, tucked out of the way. This doesn't mean cleaning the enotire studio, it just means keeping the area immediately around the desk, easel, pottery wheel, etc. clean each night. Discard trash or unnecessary materials and wipe down dirty surfaces. Endeavor to leave the workspace in a way that you can sit down the next day and start working immediately, without having to do any work or tidying..Even if the rest of your studio is a bit disorganized, an organized workspace will help you get down to business every time you wanot to make art. As visual people, a lot of artist clutter comes from a desire to keep track of supplies visually instead of tucked out of sight. By using jars, old glasses, vases, and cheap, clear plastic drawers, you can keep things in sight without leaving it strewn about haphazardly. Some ideas, beyond those just menotioned, include:..Canvas shoe racks on the back of the door.Wine racks with cups in each slot to hold pens pencils.Plastic restauranot squirt bottles for painot, pigmenot, etc. Simply string up the wires across a wall or along the ceiling and use them to hold essenotial papers that you don't wanot to cut or ruin with tacks or tape. Cheap and easy, this is also a good way to handle papers and ideas you touch regularly or need to pin up and down for inspiration. Shelving is an artist's best friend and is a cheap and easy way to get more room in your studio or art space. Don't be afraid to get up high either, especially for infrequenotly used supplies. The upper reaches of the room are often the most under-utilized, but provide vital space for all your tools and materials. Turning one wall inoto a chalkboard gives you a perfect space for ideas, sketches, and planning without requiring extra equipmenot or space. You can even use it for smaller areas. Painot over jars or storage equipmenot, allowing you to relabel them with chalk as your needs change. A lot of disorganization comes when you keep moving the location of things, trying to optimize your space by reorganizing frequenotly. This usually has the opposite effect, leading to lost items and uncertainoty when cleaning, but an afternoon with a label maker can solve everything. Instead of spending all of your menotal energy looking for or storing things, you can just follow the labels, freeing your mind to think about art. Once a monoth, do a purge of your studio. If it isn't essenotial or part of a project, either throw it out or file it away for later. Artists are constanotly making new things, experimenoting, and making a mess. This is a good thing, but only if you set aside time to declutter. It may not be fun at the momenot, but it is a lot more fun than spending 30 minutes digging through junk to find the right painot or an old sketch..Don't be senotimenotal here. If you haven't used it in the last six monoths there is little chance you'll use it in the next six monoths. Toss it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (882 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "e-summary= If you're a photographer, keep all the necessary lens, cords, and batteries in the same quadranot of your home or studio. As visual people, a lot of artist clutter comes from a desire to keep track of supplies visually instead of tucked out of sight. Wine racks with cups in each slot to hold pens pencils. Turning one wall inoto a chalkboard gives you a perfect space for ideas, sketches, and planning without requiring extra equipmenot or space. A lot of disorganization comes when you keep moving the location of things, trying to optimize your space by reorganizing frequenotly. Artists are constanotly making new things, experimenoting, and making a mess.\n",
      "----------------\n",
      "a-summary= some ideas include essenotial supplies area - - the things you use every day. the upper reaches of the room are often the most under - used, but provide vital space for all your tools and materials. for infrequenotly used supplies, canvas shoe racks on the back of the door can hold pens pencils.\n",
      "----------------\n",
      "t5-summary= .Organize your workspace..Keep a chalkboard inoto a wall...............Use wires to hold art supplies.Reorganize your work area.... the floor.Make labels...Declutter once in a while...........Trash it..\n",
      "----------------\n",
      "ss-summary= a desk.oto a wall.. the floor.Organize your workspace.......Trash it...Clean out the clutter........Reorganize your workspace.. organize your workspace.reorganize your upper reaches of the room..Declutter once in a while.........Make labels.................Stick to organizing..........\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 3666\n",
      "See the image for how this drawing develops step-by-step. However, there is an importanot detail: the following drawings are to examine it, and then, to create something unique..Use the lines to create the image shape and sections.Fill appeared sections with differenot patterns ornamenots.Add text if needed, for example NeoPopRealism is 25! .Add a colored strip on the top, any color you wish. Painoting a mural always requires some preparation. Youll need equipmenot and effort, but planning and attenotion to detail will help you succeed. Painoting a mural requires a suitable location, with the right surface that can be painoted..This surface should be smooth and flat. However, even rough-textured surfaces can be used for your NeoPopRealist mural project. For exterior projects that last for years, using a newer 100% acrylic exterior painot would be your best choice. For inoterior walls, use latex painots. Latex offer easier cleanup and lower costs. By measuring the total wall area to be covered, the total amounot of painot can be calculated, but since this mural painoting requires two colors - white and black - figuring the actual area to be painoted each color is necessary to allow purchasing the right amounot of each one..Large walls backgrounds may be rolled or sprayed with a white painot sprayer, where details may be added with brushes.Painots are sensitive to high temperatures, humidity, direct sunlight, however, the inoterior projects do not have many complications. In public places, keeping the mural protected may require attenotion. For that reason, if you make your NeoPopRealist mural dedicated to its 25-year anniversary in school or office, you can consider using varnish for your mural. See sample above. The design will give you a sense of proportion. You will have unique requiremenots and elemenots. Use a sketch and measure at scale the distances and locations of various poinots of your subject. Measuring key features will help you calculate the amounot of painot when each feature is idenotified by its color. If the surface is low, the whole mural can be painoted standing on the ground or from a stepladder. For higher work, you may have to renot a scaffold. Mark the horizonotal and vertical lines. Use white painot as background. Then begin marking, using your scaled sketch, the location of key elemenots of objects, located in the foreground. Everything depends on the complexity of your mural. If you are confidenot in your artistic results, you may choose to draw all of the details in freehand. Be careful, keep clean transition edges from one color (black) to another (white). However, mistakes can be touched up later. Always allow fresh color to dry before proceeding to the drawing. An example would be painoting a large patterns use big brushes, limbs, use small brushes for tiny and detailed patterns. If you have a drip or run, painot over it with the color painot appropriate for that location. Sharpen lines and patterns if t are blurred. If it is inotended to last a long time or if it is on a surface that require cleaning, overcoat your mural project with a clear sealer. However, if you won't be able to involve more than 16 percenot of your brain's grays matter, you'll end up with the primitive crafting of patterns or even worse, with doodling or so-called zen-doodling. But to create the NeoPopRealist ART one needs the abilities, which can be developed in talenoted people by studying using Nadia Russ' Neopoprealist instructional books. Other, the copycats' self-promotional superficial books will teach you only how to doodle because t have nothing in common with visual arts and its mission.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "e-summary= See the image for how this drawing develops step-by-step. However, there is an importanot detail: the following drawings are to examine it, and then, to create something unique..Use the lines to create the image shape and sections. Painoting a mural always requires some preparation. Painoting a mural requires a suitable location, with the right surface that can be painoted..This surface should be smooth and flat. Use a sketch and measure at scale the distances and locations of various poinots of your subject. But to create the NeoPopRealist ART one needs the abilities, which can be developed in talenoted people by studying using Nadia Russ' Neopoprealist instructional books.\n",
      "----------------\n",
      "a-summary= painoting a mural requires a suitable location, with the right surface that can be painoted. using a newer 100 % acrylic exterior painot would be your best choice. using latex painot can also be used to lower costs and lower costs. use this information to help you calculate the amounot of painot.\n",
      "----------------\n",
      "t5-summary= elemenots.For exterior walls, use acrylic painot.For interior walls, spray the painot with a paintbrush.For interior walls, cover the surface with a protective coating.Attend your attention to detail.Recognize the complexity of your project.Use color for background.Consider varnishing.Try to protect the surface.Know how much time and effort you will have to spend on the project.Some people think that drawing is an art form.Some people think that\n",
      "----------------\n",
      "ss-summary= Determine the cost of the painot. a sketch. an image. its structure. that drawing is an art form.Some people think that drawing is an art form. see the image.not.. not..... an art form. andNadia Russ' NeoPopRealist instructional books. learn how to draw.enoted.ot.ot.... only\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TEST Loop for Abstractive and Extractive summarization\n",
    "\n",
    "icount = 0\n",
    "\n",
    "for article in merged_df['article_pp2']:\n",
    "    if len(article) > 200:\n",
    "        print(\"Article Len=\", len(article))\n",
    "        print(article)\n",
    "        e_summary = generate_extractive_summary(article, min_summary_length=50)\n",
    "        a_summary = generate_abstractive_summary(article, model = abstractive_summarizer_model)\n",
    "        t5_summary = generate_abstractive_summary_T5(article)\n",
    "        all_summary = e_summary + \".\" + a_summary + \".\" + t5_summary + \".\"\n",
    "        s_s_summary = generate_abstractive_summary_T5(all_summary)\n",
    "        \n",
    "        print(\"----------------\")    \n",
    "        print(\"e-summary=\",e_summary)\n",
    "        print(\"----------------\")    \n",
    "        print(\"a-summary=\",a_summary)\n",
    "        print(\"----------------\")    \n",
    "        print(\"t5-summary=\",t5_summary)\n",
    "        print(\"----------------\")    \n",
    "        print(\"ss-summary=\",s_s_summary)\n",
    "        print(\"-------------------------------------------------------------------------------------------------\") \n",
    "        icount +=1\n",
    "\n",
    "        if icount > 10:\n",
    "            break \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5ff385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3,4,5,6,7,8,9,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (882 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,17,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2226 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23,24,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe len= 10\n",
      "e_summ len= 29\n",
      "a_summ len= 29\n",
      "t5_summ len= 29\n",
      "ss_summ len= 29\n"
     ]
    }
   ],
   "source": [
    "# Generate summaries for the articles using the different approaches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "e_list = []\n",
    "a_list = []\n",
    "t5_list = []\n",
    "sum_sum_list = []\n",
    "\n",
    "iCount = 0\n",
    "\n",
    "for article in merged_df['article_pp2']:\n",
    "    #print(article)\n",
    "    print(iCount, end=\",\")\n",
    "    iCount =  iCount + 1\n",
    "    \n",
    "    e_summary = generate_extractive_summary(article, min_summary_length=100)\n",
    "    a_summary = generate_abstractive_summary(article, model = abstractive_summarizer_model)\n",
    "    t5_summary = generate_abstractive_summary_T5(article)\n",
    "    all_summary = e_summary + \".\" + a_summary + \".\" + t5_summary + \".\"\n",
    "    s_s_summary = generate_abstractive_summary(all_summary, model = abstractive_summarizer_model)\n",
    "    \n",
    "    e_list.append(e_summary)\n",
    "    a_list.append(a_summary)\n",
    "    t5_list.append(t5_summary)\n",
    "    sum_sum_list.append(s_s_summary)\n",
    "\n",
    "\n",
    "print(\"Dataframe len=\", len(how2_df))\n",
    "print(\"e_summ len=\", len(e_list))\n",
    "print(\"a_summ len=\", len(a_list))\n",
    "print(\"t5_summ len=\", len(t5_list))\n",
    "print(\"ss_summ len=\", len(sum_sum_list))\n",
    "\n",
    "merged_df['e_summarization'] = e_list\n",
    "merged_df['a_summarization'] = a_list\n",
    "merged_df['t5_summarization'] = t5_list\n",
    "merged_df['ss_summarization'] = sum_sum_list\n",
    "\n",
    "merged_df.to_csv(os.getcwd() + \"/data/merged_df_with_Summarization.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ba03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a155e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue for Extractive Summarization\n",
      "\t\trouge-1:\tP: 30.99\tR: 19.04\tF1: 22.28\n",
      "\t\trouge-2:\tP:  6.76\tR:  3.53\tF1:  4.42\n",
      "\t\trouge-3:\tP:  2.55\tR:  1.19\tF1:  1.57\n",
      "\t\trouge-4:\tP:  1.34\tR:  0.58\tF1:  0.80\n",
      "\t\trouge-l:\tP: 25.10\tR: 15.85\tF1: 18.69\n",
      "\t\trouge-w:\tP: 14.69\tR:  3.52\tF1:  5.41\n",
      "Rogue for Abstractive Summarization\n",
      "\t\trouge-1:\tP: 28.89\tR: 23.81\tF1: 24.65\n",
      "\t\trouge-2:\tP:  5.76\tR:  4.66\tF1:  4.89\n",
      "\t\trouge-3:\tP:  1.85\tR:  1.37\tF1:  1.52\n",
      "\t\trouge-4:\tP:  0.73\tR:  0.47\tF1:  0.57\n",
      "\t\trouge-l:\tP: 24.68\tR: 20.42\tF1: 21.44\n",
      "\t\trouge-w:\tP: 14.74\tR:  5.23\tF1:  7.36\n",
      "Rogue for T5 Summarization\n",
      "\t\trouge-1:\tP: 33.25\tR: 25.44\tF1: 26.63\n",
      "\t\trouge-2:\tP:  6.78\tR:  4.90\tF1:  5.40\n",
      "\t\trouge-3:\tP:  1.81\tR:  1.30\tF1:  1.47\n",
      "\t\trouge-4:\tP:  0.66\tR:  0.44\tF1:  0.52\n",
      "\t\trouge-l:\tP: 29.55\tR: 22.52\tF1: 24.20\n",
      "\t\trouge-w:\tP: 17.88\tR:  5.79\tF1:  8.15\n",
      "Rogue for SS Summarization\n",
      "\t\trouge-1:\tP: 28.17\tR: 24.12\tF1: 24.68\n",
      "\t\trouge-2:\tP:  5.58\tR:  4.77\tF1:  4.93\n",
      "\t\trouge-3:\tP:  1.86\tR:  1.44\tF1:  1.58\n",
      "\t\trouge-4:\tP:  0.80\tR:  0.53\tF1:  0.64\n",
      "\t\trouge-l:\tP: 24.40\tR: 20.71\tF1: 21.61\n",
      "\t\trouge-w:\tP: 14.44\tR:  5.32\tF1:  7.45\n"
     ]
    }
   ],
   "source": [
    "# Calculate Rogue scores for the summarization that was just created. \n",
    "\n",
    "hypo=merged_df['summary'].tolist()\n",
    "refe1=merged_df['e_summarization'].tolist() #[reference]\n",
    "refe2=merged_df['a_summarization'].tolist() #[reference]\n",
    "refe3=merged_df['t5_summarization'].tolist() #[reference]\n",
    "refe4=merged_df['ss_summarization'].tolist() #[reference]\n",
    "\n",
    "print(\"Rogue for Extractive Summarization\")\n",
    "print_rogue_scores(hypo,refe1)    \n",
    "print(\"Rogue for Abstractive Summarization\")\n",
    "print_rogue_scores(hypo,refe2)  \n",
    "print(\"Rogue for T5 Summarization\")\n",
    "print_rogue_scores(hypo,refe3)        \n",
    "print(\"Rogue for SS Summarization\")\n",
    "print_rogue_scores(hypo,refe4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75bf487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0d7cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:14:52.778651\n"
     ]
    }
   ],
   "source": [
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef9fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
