{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa1eed7",
   "metadata": {},
   "source": [
    "#  Running our models on the How2/WikiHow/CNN data. \n",
    "\n",
    "Following are the high level steps we are following in this notebook:\n",
    "* **Load Test Data :** Summary provided with the article.  \n",
    "* **Use PreProcessed3 data  :**  Pre-Processed 3 data has following details:\n",
    " * Remove Special Characters from Text\n",
    " * Remove Stop Words from Text\n",
    " * Lemmatize Text\n",
    " * Remove invalid and non-english words. \n",
    "* **Execute following Models  :**  We are executing multiple models including:\n",
    " * Extractive Summary Model (BERT)\n",
    " * Abstractive Summary Model (BERT2BERT for CNN/Dailymail)\n",
    " * Abstractive T5 Model (pre-trained model that was trained on our data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260a934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "##############\n",
    "## INSTALLS ##\n",
    "##############\n",
    "\n",
    "#!pip install bert-extractive-summarizer\n",
    "#!pip install transformers\n",
    "#!pip install neuralcoref\n",
    "#!pip install datasets==1.0.2\n",
    "#!pip install git-python==1.0.3\n",
    "#!pip install sacrebleu==1.4.12\n",
    "#!pip install rouge_score\n",
    "#!pip install rouge-metric\n",
    "\n",
    "#!pip install rouge\n",
    "#!pip install py-rouge\n",
    "#!pip install pyrouge\n",
    "#!pip install torch\n",
    "#!pip install sentencepiece\n",
    "#!pip install nlp\n",
    "\n",
    "#!python -m nltk.downloader all\n",
    "#!python -m spacy download en_core_web_md\n",
    "#!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30a36b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########\n",
    "# IMPORTS #\n",
    "###########\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_md\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import csv\n",
    "import rouge\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "#from rouge_score import rouge_scorer\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  \n",
    "from transformers import BertTokenizer, EncoderDecoderModel\n",
    "from tqdm import tqdm_pandas\n",
    "from tqdm import tqdm\n",
    "from summarizer import Summarizer\n",
    "from simplet5 import SimpleT5\n",
    "from datetime import datetime\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2e99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package stopwords to /home/sunitc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "###############\n",
    "# GLOBAL VARS #\n",
    "###############\n",
    "start_time = datetime.now()\n",
    "\n",
    "aggregator='Avg'\n",
    "apply_avg = aggregator == 'Avg'\n",
    "apply_best = aggregator == 'Best'\n",
    "vectorizer = TfidfVectorizer()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")  \n",
    "abstractive_summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
    "extractive_summarizer_model = Summarizer()\n",
    "modelt5 = SimpleT5()\n",
    "modelt5.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9325fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c08ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>summary</th>\n",
       "      <th>article</th>\n",
       "      <th>data_source</th>\n",
       "      <th>article_pp1</th>\n",
       "      <th>article_pp2</th>\n",
       "      <th>article_pp3</th>\n",
       "      <th>num_words_article</th>\n",
       "      <th>num_sentences_article</th>\n",
       "      <th>num_words_summary</th>\n",
       "      <th>num_sentences_summary</th>\n",
       "      <th>num_words_article_pp1</th>\n",
       "      <th>num_sentences_article_pp1</th>\n",
       "      <th>num_words_article_pp2</th>\n",
       "      <th>num_sentences_article_pp2</th>\n",
       "      <th>num_words_article_pp3</th>\n",
       "      <th>num_sentences_article_pp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>in order to put photographic emulsion on water...</td>\n",
       "      <td>my name is anthony maddaloni and i 'm going to...</td>\n",
       "      <td>How2</td>\n",
       "      <td>photograph emulsion heat emulsion light tight ...</td>\n",
       "      <td>now photographs have an emulsion on them .and ...</td>\n",
       "      <td>photograph emulsion heat emulsion light tight ...</td>\n",
       "      <td>149</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>the size of a paintball gun site depends on it...</td>\n",
       "      <td>my name is scott mckay and today we are shooti...</td>\n",
       "      <td>How2</td>\n",
       "      <td>standing front american fort right going talk ...</td>\n",
       "      <td>we are standing in fronot of the american fort...</td>\n",
       "      <td>standing front american fort right going talk ...</td>\n",
       "      <td>429</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>18</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                            summary  \\\n",
       "4            4  in order to put photographic emulsion on water...   \n",
       "41          41  the size of a paintball gun site depends on it...   \n",
       "\n",
       "                                              article data_source  \\\n",
       "4   my name is anthony maddaloni and i 'm going to...        How2   \n",
       "41  my name is scott mckay and today we are shooti...        How2   \n",
       "\n",
       "                                          article_pp1  \\\n",
       "4   photograph emulsion heat emulsion light tight ...   \n",
       "41  standing front american fort right going talk ...   \n",
       "\n",
       "                                          article_pp2  \\\n",
       "4   now photographs have an emulsion on them .and ...   \n",
       "41  we are standing in fronot of the american fort...   \n",
       "\n",
       "                                          article_pp3  num_words_article  \\\n",
       "4   photograph emulsion heat emulsion light tight ...                149   \n",
       "41  standing front american fort right going talk ...                429   \n",
       "\n",
       "    num_sentences_article  num_words_summary  num_sentences_summary  \\\n",
       "4                       9                 54                      3   \n",
       "41                     19                 65                      3   \n",
       "\n",
       "    num_words_article_pp1  num_sentences_article_pp1  num_words_article_pp2  \\\n",
       "4                      56                          1                    124   \n",
       "41                    193                          1                    396   \n",
       "\n",
       "    num_sentences_article_pp2  num_words_article_pp3  \\\n",
       "4                           8                     48   \n",
       "41                         18                    179   \n",
       "\n",
       "    num_sentences_article_pp3  \n",
       "4                           1  \n",
       "41                          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########\n",
    "# DATA #\n",
    "########\n",
    "\n",
    "\n",
    "# setting number of rows to low number so notebook runs in minutes and not hours. \n",
    "num_rows_each_df = 10\n",
    "\n",
    "cnn_dailymail_df = pd.read_csv(os.getcwd() + \"/data/cnn_dm_df.csv\",encoding = \"utf-8\")\n",
    "wikihow_df = pd.read_csv(os.getcwd() + \"/data/wikihow_df.csv\",encoding = \"utf-8\")\n",
    "how2_df = pd.read_csv(os.getcwd() + \"/data/how2_df.csv\",encoding = \"utf-8\")\n",
    "\n",
    "wikihow_df = wikihow_df[(wikihow_df.article_pp1.str.len() < 3700) & (wikihow_df.summary.str.len() > 300)]\n",
    "how2_df = how2_df[(how2_df.article_pp1.str.len() < 3700) & (how2_df.summary.str.len() > 300)]\n",
    "#cnn_dailymail_df = cnn_dailymail_df[(cnn_dailymail_df.article_pp1.str.len() > 300) & (cnn_dailymail_df.summary.str.len() > 100)]\n",
    "\n",
    "if len(wikihow_df) > num_rows_each_df:\n",
    "    wikihow_df = wikihow_df.head(num_rows_each_df)\n",
    "    \n",
    "if len(how2_df) > num_rows_each_df:\n",
    "    how2_df = how2_df.head(num_rows_each_df)\n",
    "    \n",
    "if len(cnn_dailymail_df) > num_rows_each_df:\n",
    "    cnn_dailymail_df = cnn_dailymail_df.head(num_rows_each_df)\n",
    "    \n",
    "merged_df = pd.concat([how2_df, wikihow_df,cnn_dailymail_df], axis=0)\n",
    "merged_df = merged_df[merged_df.article_pp1.str.len() > 250]\n",
    "\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f0b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51419e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# HELPER FUNCTIONS #\n",
    "####################\n",
    "\n",
    "\n",
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "\n",
    "def RemoveIntroFromText(script):\n",
    "    sentences = [x for x in script.sents]\n",
    "    i=0\n",
    "    new_text=\"\"\n",
    "    print(\"Original text: \\n\")\n",
    "    displacy.render(script, jupyter=True, style='ent')\n",
    "    print(\"Some preprocessing details: \\n************\\n\")\n",
    "    is_intro=False\n",
    "    \n",
    "    for sent in sentences:\n",
    "        at_least_one_person=0\n",
    "        print(\"Sentence \", i, \": \", sentences[i])\n",
    "        d= dict([(str(x), x.label_) for x in nlp(str(sent)).ents])\n",
    "        print(d)\n",
    "        if len(d)>0:\n",
    "            print(d)\n",
    "            for key in d:\n",
    "                #print(\"key:\",key, \"; value=\", d[key])\n",
    "                #print(sent)\n",
    "                if (d[key]==\"PERSON\"):\n",
    "                    at_least_one_person+=1\n",
    "        if \"expertvillage\" in str(sent).lower() or \"expert village\" in str(sent).lower():\n",
    "            is_intro=True\n",
    "        if (at_least_one_person>0):\n",
    "            print(\"the sentence has at least one person:\")\n",
    "            print(\"Sentence \", i, \": \", sentences[i])    \n",
    "        if (i<4 and (at_least_one_person>0  or is_intro)):\n",
    "            print(\"the sentence is likely an introduction\")\n",
    "            new_text=''\n",
    "        else:\n",
    "            new_text+=str(sent)\n",
    "            if not (str(sent).strip()[-1] in string.punctuation): \n",
    "                print (\"Missing punctuation at the end\", sent, \"; last char is \", str(sent).strip()[-1])\n",
    "                new_text+=\". \"\n",
    "        i+=1\n",
    "    print(\"\\n*************\\nNew text, hopefully without person introduction:\\n**********\\n\", new_text)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def RemoveIntroFromTextMiddle(text):\n",
    "    script = nlp(text)\n",
    "    sentences = [x for x in script.sents]\n",
    "    #print(\"sentences.....\")\n",
    "    #print(sentences)\n",
    "    i=0\n",
    "    new_text=\"\"\n",
    "    print(\"Original text: \\n\")\n",
    "    displacy.render(script, jupyter=True, style='ent')\n",
    "    print(\"Some preprocessing details: \\n************\\n\")\n",
    "    is_intro=False\n",
    "    \n",
    "    for sent in sentences:\n",
    "        at_least_one_person=0\n",
    "        print(\"Sentence \", i, \": \", sentences[i])\n",
    "        d= dict([(str(x), x.label_) for x in nlp(str(sent)).ents])\n",
    "        print(d)\n",
    "        if len(d)>0:\n",
    "            print(d)\n",
    "            for key in d:\n",
    "                #print(\"key:\",key, \"; value=\", d[key])\n",
    "                #print(sent)\n",
    "                if (d[key]==\"PERSON\"):\n",
    "                    at_least_one_person+=1\n",
    "        if \"expertvillage\" in str(sent).lower() or \"expert village\" in str(sent).lower():\n",
    "            is_intro=True\n",
    "        if (at_least_one_person>0):\n",
    "            print(\"the sentence has at least one person:\")\n",
    "            print(\"Sentence \", i, \": \", sentences[i])    \n",
    "        if (i<4 and (at_least_one_person>0  or is_intro)):\n",
    "            print(\"skipping the sentence as it is likely an introduction\")\n",
    "            #new_text=''\n",
    "        else:\n",
    "            new_text+=str(sent)\n",
    "            if not (str(sent).strip()[-1] in string.punctuation): \n",
    "                print (\"Missing punctuation at the end\", sent, \"; last char is \", str(sent).strip()[-1])\n",
    "                new_text+=\". \"\n",
    "        i+=1\n",
    "    print(\"\\n*************\\nNew text, hopefully without person introduction:\\n**********\\n\", new_text)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def RemoveIntroFromTextNonVerbose(script):\n",
    "    sentences = [x for x in script.sents]\n",
    "    i=0\n",
    "    new_text=\"\" \n",
    "    #displacy.render(script, jupyter=True, style='ent') \n",
    "    is_intro=False\n",
    "    \n",
    "    for sent in sentences:\n",
    "        at_least_one_person=0\n",
    "        d= dict([(str(x), x.label_) for x in nlp(str(sent)).ents])\n",
    "        if len(d)>0:\n",
    "            for key in d:\n",
    "                if (d[key]==\"PERSON\"):\n",
    "                    at_least_one_person+=1\n",
    "        if \"expertvillage\" in str(sent).lower() or \"expert village\" in str(sent).lower():\n",
    "            is_intro=True\n",
    "        if (i<4 and (at_least_one_person>0  or is_intro)):\n",
    "             new_text=''\n",
    "        else:\n",
    "            new_text+=str(sent)\n",
    "            if not (str(sent).strip()[-1] in string.punctuation): \n",
    "                 new_text+=\". \"\n",
    "        i+=1\n",
    "    return new_text\n",
    "\n",
    "\n",
    "#Raw Text Summarization\n",
    "def generate_abstractive_summary(raw_string, model = abstractive_summarizer_model, max_length=512):\n",
    "    \"\"\"This function produces an abstractive summary for a given article\"\n",
    "    Params:\n",
    "    raw_string: an article string.\n",
    "    model: An abstractive summarizer model\"\"\"\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(raw_string, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return output_str[0]\n",
    "\n",
    "\n",
    "def generate_extractive_summary(raw_string, model = extractive_summarizer_model, min_summary_length = 50):\n",
    "    \"\"\"This function produces an extractive summary for a given article\"\n",
    "    Params:\n",
    "    raw_string: an article string.\n",
    "    model: An extractive summarizer model\"\"\"\n",
    "    output_str = model(raw_string, min_length = min_summary_length)\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def process_article(text):\n",
    "    #print(\"proces article\")\n",
    "    article = text.split(\".\")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        #print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(in_text, top_n=5):\n",
    "    summarize_text = []\n",
    "    try:\n",
    "        # Step 1 - Read text anc split it\n",
    "        sentences =  process_article(in_text)\n",
    "        # Step 2 - Generate Similary Martix across sentences\n",
    "        sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "        # Step 3 - Rank sentences in similarity martix\n",
    "        sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "        scores = nx.pagerank(sentence_similarity_graph)\n",
    "        # Step 4 - Sort the rank and pick top sentences\n",
    "        ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "        #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "        for i in range(top_n):\n",
    "            summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "        # Step 5 - Offcourse, output the summarize text\n",
    "        #print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "    except:\n",
    "        return \"\"\n",
    "    finally:\n",
    "        return \". \".join(summarize_text)\n",
    "\n",
    "def generate_abstractive_summary_T5(raw_string):\n",
    "    # using epoch 5\n",
    "    modelt5.load_model(\"t5\",\"outputs/simplet5-epoch-7-train-loss-0.9977\", use_gpu=False)\n",
    "    return modelt5.predict(raw_string)[0]\n",
    "\n",
    "#def prepare_results(p, r, f):\n",
    "#    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "def print_rogue_scores(hypo, refe):\n",
    "    scores = evaluator.get_scores(hypo, refe)\n",
    "    #scores = evaluator.get_scores(all_hypothesis, all_references)\n",
    "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "        if not apply_avg and not apply_best: # value is a type of list as we evaluate each summary vs each reference\n",
    "            for hypothesis_id, results_per_ref in enumerate(results):\n",
    "                nb_references = len(results_per_ref['p'])\n",
    "                for reference_id in range(nb_references):\n",
    "                    print('\\tHypothesis #{} & Reference #{}: '.format(hypothesis_id, reference_id))\n",
    "                    print('\\t' + '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * results_per_ref['p'][reference_id], 'R', 100.0 * results_per_ref['r'][reference_id], 'F1', 100.0 * results_per_ref['f'][reference_id]))\n",
    "                    #print('\\t' + prepare_results(results_per_ref['p'][reference_id], results_per_ref['r'][reference_id], results_per_ref['f'][reference_id]))\n",
    "            print()\n",
    "        else:\n",
    "            print('\\t' + '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * results['p'], 'R', 100.0 * results['r'], 'F1', 100.0 * results['f']))\n",
    "            #print(\"x\") #prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32a47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Rouge Evaluator  #\n",
    "####################\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                           max_n=4,\n",
    "                           limit_length=True,\n",
    "                           length_limit=100,\n",
    "                           length_limit_type='words',\n",
    "                           apply_avg=apply_avg,\n",
    "                           apply_best=apply_best,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           weight_factor=1.2,\n",
    "                           stemming=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b9373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Len= 346\n",
      "photograph emulsion heat emulsion light tight space red photographic safe light paint photographic emulsion onto paper print traditional photographic technique dark room like especially make photograph necessarily flat plastic put paper make card make even really beautiful image one way kind create style photographic emulsion painted onto paper\n",
      "----------------\n",
      "e-summary= photograph emulsion heat emulsion light tight space red photographic safe light paint photographic emulsion onto paper print traditional photographic technique dark room like especially make photograph necessarily flat plastic put paper make card make even really beautiful image one way kind create style photographic emulsion painted onto paper\n",
      "----------------\n",
      "a-summary= emulsion painted onto paper onto paper. traditional photographic technique is dark room like make - or - make - card paint painted on paper. use the emulsion to create a style photographic emulsion on paper and print. use this technique to make a perfect picture of your image or image.\n",
      "----------------\n",
      "t5-summary= emulsion light tight space red photographic safe light paint photograph emulsion onto paper print traditional photographic technique dark room like especially make beautiful image one way kind create style photographic emulsion painted onto paper print traditional photographic technique dark room like especially make even really beautiful image one way kind make card make photo emulsion painted onto paper print traditional photographic technique dark room like especially make very beautiful image one way kind make card make card make card make card make card make card make card make card make card make card make card make card make card\n",
      "----------------\n",
      "ss-summary= emulsion heat emulsion light tight space red photographic safe light paint photographic emulsion onto paper print traditional photographic technique dark room like especially make photograph necessarily flat plastic put paper make card make photo emulsion painted onto paper.emulsion light tight space red photographic safe light paint photograph emulsion onto paper print traditional photographic technique dark room like especially make even really beautiful image one way kind create style photographic emulsion painted onto paper.emulsion painted onto paper print.emulsion light tight space red photographic\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 1043\n",
      "standing front american fort right going talk field size thing need good field need good safe area people go take mask look gun make sure everything working right cool eating snack access water always good bring cooler water need anyone getting sick two separate safe area first safe area park vehicle second safe area staging area decide kind game going play come area get go back safe area wait everybody else always good let neighbor know wo call cop need know field large enough stray going enter anyone direction game recommend play city unless field piece property twelve half acre two good size two story fort work got mean place really whole lot going first hard work many people love game see stuff like time good size field always help wooded area like wood ball scenario thing play inflatable bunker play nice back lot well whatever keep safe know gun going play normal field keep gun foot per second always require mask field good thing keep covered liability form talk lawyer get simple liability form drawn keep everybody trouble\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= standing front american fort right going talk field is need good field field. the fort work got mean place good enough to play in a game good size two - story fort work great size two story two story story two two story stories tall and four - bedroom two - star fort work get go back safe area.\n",
      "----------------\n",
      "t5-summary= good safe area park vehicle second safe area decide kind game going play city unless field piece property twelve half acre two good size two story fort work got mean place really whole lot going first hard work many people love game recommend play city unless field piece property twelve half acre two good size two story fort work got mean place really whole lot going first hard work many people love game recommend play city unless field piece property twelve half acre two good size two story fort work got mean place really whole lot going first hard work many people\n",
      "----------------\n",
      "ss-summary= . - story fort work get go back safe area decide kind game going play city unless field piece property twelve half acre two good size two story fort work got mean place really whole lot going first hard work many people love game recommend play city..good safe area park vehicle second safe area decide kind game going play city unless field piece property twelve half acre two good size two story fort work got mean place really whole lot going first hard work many people love game recommend play city.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 495\n",
      "best thing would boot come ankle support like great boot last long time waterproof depending situation place would want research figure best boot would situation whether warmth comfort support waterproof come rock climbing shoe variety different type gym like use slipper easy easy outdoors technical climbing might use lace toe box hike wood wearing approach shoe approach shoe climbing rubber like rock climbing shoe solid toe box like boot shoe segment shoe climbing name scott north carolina\n",
      "----------------\n",
      "e-summary= best thing would boot come ankle support like great boot last long time waterproof depending situation place would want research figure best boot would situation whether warmth comfort support waterproof come rock climbing shoe variety different type gym like use slipper easy easy outdoors technical climbing might use lace toe box hike wood wearing approach shoe approach shoe climbing rubber like rock climbing shoe solid toe box like boot shoe segment shoe climbing name scott north carolina\n",
      "----------------\n",
      "a-summary= best thing would boot come ankle support like great boot last long time waterproof depending situation place's location. the best thing to boot would be waterproof come toe - to - toe with the help of footwear and footwear as well as a footwear expert's choice of sportswear.\n",
      "----------------\n",
      "t5-summary= boot would support waterproof best boot would support waterproof come rock climbing shoe variety different type gym like use slipper easy easy outdoors technical climbing might use lace up toe box hike wood wearing approach shoe for rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber\n",
      "----------------\n",
      "ss-summary= best boot would support waterproof come rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing rubber like rock climbing\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 472\n",
      "answer question find penalty shoplifting well shoplifting act stealing merchandise retail store type shop shoplifting penalty going vary state state sometimes municipality municipality going want check particular state statute dealing shoplifting county reside statute perhaps best one consult know particular penalty going particular charge shoplifting criminal attorney area law someone dealt shoplifting area person know judge particular area robert todd thank watching\n",
      "----------------\n",
      "e-summary= answer question find penalty shoplifting well shoplifting act stealing merchandise retail store type shop shoplifting penalty going vary state state sometimes municipality municipality going want check particular state statute dealing shoplifting county reside statute perhaps best one consult know particular penalty going particular charge shoplifting criminal attorney area law someone dealt shoplifting area person know judge particular area robert todd thank watching\n",
      "----------------\n",
      "a-summary= the state legislature is considering a state statute dealing with shoplifting. the state constitution prohibits shoplifting for shoplifting or shoplifting in the state. the code of conduct is known as the \" shoplifting act of the union, \" and it's not known if it is a shoplifting law.\n",
      "----------------\n",
      "t5-summary= penalty going vary state state sometimes municipality municipality going want check particular state statute dealing shoplifting county reside statute perhaps best one consult know particular charge shoplifting criminal attorney area law someone dealt shoplifting area person know judge particular charge shoplifting crime judge particular charge shoplifting act stealing merchandise retail store type shoplifting act stealing merchandise retail store type shoplifting act stealing merchandise retail store type shoplifting penalty going vary state state sometimes municipality going want check particular state statute dealing shoplifting county reside statute perhaps best to consult know particular\n",
      "----------------\n",
      "ss-summary= penalty going vary state state sometimes municipality municipality going want check particular state statute dealing shoplifting county reside statute perhaps best to consult know particular.penalty going vary state state sometimes municipality going want check particular state statute dealing shoplifting county reside statute perhaps best to consult know particular.penalty going vary state state sometimes municipality going want check particular state statute dealing shoplifting county reside statute perhaps best to consult know particular.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 303\n",
      "like octave already learned octave octave want hear nice ringing sound play string note e string like know hit note e string tune hear little bit ringing sound underneath like octave could also play like octave play string note e string together octave practice like octave help tune also help play tune\n",
      "----------------\n",
      "e-summary= like octave already learned octave octave want hear nice ringing sound play string note e string like know hit note e string tune hear little bit ringing sound underneath like octave could also play like octave play string note e string together octave practice like octave help tune also help play tune\n",
      "----------------\n",
      "a-summary= like octave already learned to play like octave play string note e string e string tune e string. like octave could also help tune down. the like - tune will also help play tune and play the tune also. the act of octave already has already learned an easy way to play the piano.\n",
      "----------------\n",
      "t5-summary= octave octave play octave help tune learn octave also play want to hear little bit ringing sound play string note e string together like octave want to hear hit note e string tune learn octave already learned octave want to hear little bit ringing sound under like octave play string note e string together get ready to plays\n",
      "----------------\n",
      "ss-summary= octave help tune also help play tune. octave help tune also help play tune. octave help tune also help to play the piano.play octave help tune also help to play the piano.play octave help tune also help to play the piano.play octave help tune and learn how to play the piano.play octave help tune together.play music with ease.play music with ease.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 661\n",
      "today going discus safety rock climbing safety procedure would include partner making sure harness right making figure eight knot correct make sure belay setup correctly safety aspect would knowing environment around people climbing somebody climbing outside want make sure wearing helmet piece rock fall top hit head safety aspect would making sure use climbing command make sure belay ready begin climbing thing learn local indoor rock climbing gym qualified rock climbing guide stress try learn safety procedure go climbing indoor climbing gym great place environment learn many many aspect rock climbing safety procedure thank safety procedure rock climbing\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= the discus safety procedure would include partner making sure harness right. the rock climbing safety procedure will include a guide on how to use the helmet piece rock fall top. do you know a hero? nominations are open for 2012 british rock climbing news. follow all the news with sport news.\n",
      "----------------\n",
      "t5-summary= safety procedure go climbing indoor rock climbing gym great place environment learn many many aspect rock climbing safety procedure would include partner making sure harness right making figure eight knot correct make sure belay setup correctly safety aspect would knowing environment around people climbing somebody climbing outside want make sure wearing helmet piece rock fall top hit head safety aspect would knowing environment around people climbing somebody climbing outside want make sure belay setup correctly safety aspect would knowing environment around people climbing somebody climbing outside want make sure belay setup correctly safety aspect would knowing environment around people climbing somebody climbing outside want make sure wearing helmet piece\n",
      "----------------\n",
      "ss-summary= . the discus safety procedure would include partner making sure harness right.the rock climbing safety procedure will include a guide on how to use the helmet piece rock fall top hit head.find out who you think is a hero in the rock climbing community. nominate your favorite rock climbing hero!\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 961\n",
      "let talk talk stop dog chasing tail one first thing need try determine dog chasing tail overly hyperactive enjoyable activity something put cue dog seem enjoy cue word chase tail spin circle would reward hopefully behavior diminish couple thing take care right bat look dog diet dog diet high something like grain could causing hyperactivity may allergic might want work somebody interested nutrition example small pet food distributor area veterinarian would first step question dog getting enough mental physical exercise lady came four year old rescue getting enough physical exercise getting enough mental stimulation also twenty pound overweight got weight gave plenty think behavior every get little excited chase tail nothing like used try thing dog still chasing tail might want probably need go talk veterinarian might need look obsessive compulsive disorder would rare thing medication market try deal little bit outside certainly consult professional\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= dog chase tail spin circle circle would reward hopefully behavior. small pet food distributor area veterinarian might need to look obsessively at tail. dog chasing could cause hyperactivity disorder, expert says. do you know a hero? share your thoughts with cnn ireport.\n",
      "----------------\n",
      "t5-summary= dog chasing tail one first thing need try determine dog chasing tail overly hyperactive enjoyable activity something put cue word chase tail spin circle would reward hopefully behavior diminish couple thing take care right bat look dog diet dog diet high something like grain overweight got weight gave plenty think behavior every get little excited chase tail nothing like used try thing dog still chasing tail might want probably need go talk veterinarian might need look obsessive compulsive disorder would rare thing medication market try deal little bit outside certainly consult professional pet food distributor area veterinarian would first\n",
      "----------------\n",
      "ss-summary= .chasing tail spin circle circle would reward hopefully behavior diminish couple thing take care right bat look dog chasing tail overly hyperactive enjoyable activity something put cue word chase tail spin circle circle circle would reward hopefully behavior diminish couple thing take care right bat look dog diet dog diet high.dog still chasing tail might want.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 317\n",
      "alright let play bass drum beat one one three four alright practice like separate two idea term bass figure one hand bass drum surrounding beat one beat one directly beat one four directly beat one one sound like part equation play bass drum three directly back beat play snare beat three well hi hat put together get\n",
      "----------------\n",
      "e-summary= alright let play bass drum beat one one three four alright practice like separate two idea term bass figure one hand bass drum surrounding beat one beat one directly beat one four directly beat one one sound like part equation play bass drum three directly back beat play snare beat three well hi hat put together get\n",
      "----------------\n",
      "a-summary= play bass drum beats one beat one three straight beat one. play snare beat one beat three straight straight beats. beat one beats one straight beat beat one one beat four straight beats and one beat a four straight beat beats one... you don't know how to play bass.\n",
      "----------------\n",
      "t5-summary= play bass drum beat one one three four alright practice like separate two idea term bass figure one hand bass drum surround beat one one three four directly beat one one sound like part equation play bass drum three directly back beat play snare beat three well hi hat put together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together\n",
      "----------------\n",
      "ss-summary= . bass drum beat one one three four alright let play bass drum beats one one three four one straight beat beat one one well hi hat put together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get together get\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 1095\n",
      "become comedian well reason comic become comedian youngster shy introverted insecure low self esteem enjoy like would see stand comedian thought wow look praise get look audience love ability stand front audience take control like seed time youngster oh sure grew applied job fireman lot job got job government investigator people go wow great job another stepping stone point could make money go real journey become professional stand comic path took become stand comic quit good government job struggling person struggling stand comic going open three different open night three different audition performance every night across year got first gig took three four year could actually start making decent money several agent year really need agent become successful comedian strong act got touch booking agent booking agent around country relationship would call time wanting come area country work way get booking agent send tape act get tape act someone tape club buy video camera tape never high high quality bu good enough booking agent watch tape say yep person funny kind person want hire\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= stand comic become stand comic path comic path took three years to complete. stand - up star turned stand comic turned stand - comic path takes three different auditions each night across year. stand up is the first comedy act in the united states to be successful in the theatre industry. follow the story of stand up comedian youngster who quit good government job as stand comic.\n",
      "----------------\n",
      "t5-summary= professional stand comic good government job fireman lot job got job government investigator people go wow great job another stepping stone point could actually start making decent money go real journey become professional stand comic becoming professional stand comic going open three different open night three different audition performance every year got first gig took three different open night three different audition performance every year got first gig took three different open night three different audition performance every year got first gig took three different open night three different audition performance every year got first gig took three different open night three different audition performance every year got booking\n",
      "----------------\n",
      "ss-summary= stand - up star turned stand comic turned stand - comic path comic path took three years to complete.professional stand comic go real journey become professional stand comic becoming professional stand comic going open three different open night three different audition performance every year got first gig took three different open night three different audition performance every year got booking.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 620\n",
      "interactive game inside outside inside interactive game board game make sure board game age appropriate child concept game additional interactive game house may include art craft thing two interact one another grouping child one may couple different activity going time working board game child may want play one board game little one may want play one age appropriate allow play give ownership game different group make sure interact well outside interactive game may include tag even red light green light make sure play outside interactive game location safe permission go outside remember dependable safe always time\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= interactive game inside inside inside interactive game board game board. interactive game includes art craft thing two interact one another. game may include tag even red light green light green and red light blue green. play one board game with a child and play one age appropriate game. play your own board game in the interactive game.\n",
      "----------------\n",
      "t5-summary= interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside outside interactive game inside inside interactive game appropriate child concept game dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always time dependable safe always\n",
      "----------------\n",
      "ss-summary= interactive game board. interactive game board.interactive game inside outside interactive game inside outside interactive game.interactive game inside outside interactive game.interactive game inside outside interactive game.interactive game inside outside interactive game.interactive game inside outside interactive game.\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Article Len= 2027\n",
      "photographer keep necessary lens cord battery quadrant home studio paint kept brush cleaner canvas print supply ink make group area supply make finding easier limiting search much smaller area idea include essential supply area thing use every day inspiration reference area work area infrequent secondary supply area way doesnt mean cleaning entire studio mean keeping area immediately around desk easel pottery wheel clean night discard trash unnecessary material wipe dirty surface endeavor leave way sit next day start working immediately without work even rest studio bit organized help get business every time want make art visual people lot artist clutter come desire keep track supply visually instead sight jar old glass vas cheap clear plastic drawer keep thing sight without leaving strewn haphazardly idea beyond include canvas shoe rack back door wine rack cup slot hold plastic restaurant squirt bottle paint pigment simply string wire across wall along ceiling use hold essential paper dont want cut ruin tack tape cheap easy also good way handle paper idea touch regularly need pin inspiration shelving artist best friend cheap easy way get room studio art space dont afraid get high either especially infrequently used supply upper reach room often provide vital space tool material turning one wall give perfect space idea sketch without extra equipment space even use smaller area paint jar storage equipment relabel chalk need change lot disorganization come keep moving location thing trying optimize space frequently usually opposite effect leading lost item uncertainty cleaning afternoon label maker solve everything instead spending mental energy looking thing follow label freeing mind think art month purge studio essential part project either throw file away later artist constantly making new thing making mess good thing set aside time may fun moment lot fun spending minute digging junk find right paint old sketch dont sentimental havent used last six month little chance use next six month toss\n",
      "----------------\n",
      "e-summary= \n",
      "----------------\n",
      "a-summary= studio essential supply area is infrequently used supply area way doesn't mean cleaning entire studio. work area is the place place for make art visual people lot work area way way doesnt mean cleaning all the studio. take a look at the studio and find the best possible supply area for work.\n",
      "----------------\n",
      "t5-summary= essential supply area thing keep things sight jar old glass vas cheap clear plastic drawer keep things sight without leaving strewn haphazly idea beyond include essential supply area thing use daily need pin inspiration shelving artist best friend cheap easy also good way handle paper idea touch regularly need pin inspiration shelving artist best friend cheap easy also good way handle paper idea touch regularly need pin inspiration storage bins and boxes make finding easier limiting search much smaller area idea beyond include essential supply area thing use every day inspiration reference area thing use everyday tossing\n",
      "----------------\n",
      "ss-summary= find the best possible supply area for work. essential supply area is infrequently used use daily need pin inspiration shelving artist best friend cheap easy also good way handle paper idea touch regularly need pin inspiration.find small area.find small area.find small area.\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TEST Loop for Abstractive and Extractive summarization\n",
    "\n",
    "icount = 0\n",
    "\n",
    "for article in merged_df['article_pp3']:\n",
    "    if len(article) > 200:\n",
    "        print(\"Article Len=\", len(article))\n",
    "        print(article)\n",
    "        e_summary = generate_extractive_summary(article, min_summary_length=50)\n",
    "        a_summary = generate_abstractive_summary(article, model = abstractive_summarizer_model)\n",
    "        t5_summary = generate_abstractive_summary_T5(article)\n",
    "        all_summary = e_summary + \".\" + a_summary + \".\" + t5_summary + \".\"\n",
    "        s_s_summary = generate_abstractive_summary_T5(all_summary)\n",
    "        \n",
    "        print(\"----------------\")    \n",
    "        print(\"e-summary=\",e_summary)\n",
    "        print(\"----------------\")    \n",
    "        print(\"a-summary=\",a_summary)\n",
    "        print(\"----------------\")    \n",
    "        print(\"t5-summary=\",t5_summary)\n",
    "        print(\"----------------\")    \n",
    "        print(\"ss-summary=\",s_s_summary)\n",
    "        print(\"-------------------------------------------------------------------------------------------------\") \n",
    "        icount +=1\n",
    "\n",
    "        if icount > 10:\n",
    "            break \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5ff385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,22,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,25,26,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28,29,e_summ len= 30\n",
      "a_summ len= 30\n",
      "t5_summ len= 30\n",
      "ss_summ len= 30\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "e_list = []\n",
    "a_list = []\n",
    "t5_list = []\n",
    "sum_sum_list = []\n",
    "\n",
    "iCount = 0\n",
    "\n",
    "for article in merged_df['article_pp3']:\n",
    "    #print(article)\n",
    "    print(iCount, end=\",\")\n",
    "    iCount =  iCount + 1\n",
    "    \n",
    "    e_summary = generate_extractive_summary(article, min_summary_length=100)\n",
    "    a_summary = generate_abstractive_summary(article, model = abstractive_summarizer_model)\n",
    "    t5_summary = generate_abstractive_summary_T5(article)\n",
    "    all_summary = e_summary + \".\" +  a_summary + \".\" + t5_summary + \".\"\n",
    "    s_s_summary = generate_abstractive_summary(all_summary, model = abstractive_summarizer_model)\n",
    "    \n",
    "    e_list.append(e_summary)\n",
    "    a_list.append(a_summary)\n",
    "    t5_list.append(t5_summary)\n",
    "    sum_sum_list.append(s_s_summary)\n",
    "    \n",
    "    #break \n",
    "\n",
    "\n",
    "print(\"e_summ len=\", len(e_list))\n",
    "print(\"a_summ len=\", len(a_list))\n",
    "print(\"t5_summ len=\", len(t5_list))\n",
    "print(\"ss_summ len=\", len(sum_sum_list))\n",
    "\n",
    "merged_df['e_summarization'] = e_list\n",
    "merged_df['a_summarization'] = a_list\n",
    "merged_df['t5_summarization'] = t5_list\n",
    "merged_df['ss_summarization'] = sum_sum_list\n",
    "\n",
    "merged_df.to_csv(os.getcwd() + \"/data/merged_df_with_Summarization.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ba03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a155e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue for Extractive Summarization\n",
      "\t\trouge-1:\tP:  4.43\tR:  4.93\tF1:  4.58\n",
      "\t\trouge-2:\tP:  0.58\tR:  0.69\tF1:  0.62\n",
      "\t\trouge-3:\tP:  0.05\tR:  0.04\tF1:  0.05\n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\t\trouge-l:\tP:  4.31\tR:  4.69\tF1:  4.44\n",
      "\t\trouge-w:\tP:  2.41\tR:  1.20\tF1:  1.57\n",
      "Rogue for Abstractive Summarization\n",
      "\t\trouge-1:\tP: 25.22\tR: 27.02\tF1: 25.26\n",
      "\t\trouge-2:\tP:  3.31\tR:  3.36\tF1:  3.22\n",
      "\t\trouge-3:\tP:  0.15\tR:  0.19\tF1:  0.16\n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\t\trouge-l:\tP: 22.73\tR: 23.41\tF1: 22.54\n",
      "\t\trouge-w:\tP: 12.75\tR:  5.87\tF1:  7.82\n",
      "Rogue for T5 Summarization\n",
      "\t\trouge-1:\tP: 18.14\tR: 11.76\tF1: 13.91\n",
      "\t\trouge-2:\tP:  2.03\tR:  1.23\tF1:  1.49\n",
      "\t\trouge-3:\tP:  0.07\tR:  0.04\tF1:  0.05\n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\t\trouge-l:\tP: 18.49\tR: 12.60\tF1: 14.74\n",
      "\t\trouge-w:\tP: 10.22\tR:  2.61\tF1:  4.09\n",
      "Rogue for SS Summarization\n",
      "\t\trouge-1:\tP: 24.25\tR: 26.92\tF1: 24.70\n",
      "\t\trouge-2:\tP:  3.03\tR:  3.23\tF1:  3.01\n",
      "\t\trouge-3:\tP:  0.29\tR:  0.27\tF1:  0.26\n",
      "\t\trouge-4:\tP:  0.00\tR:  0.00\tF1:  0.00\n",
      "\t\trouge-l:\tP: 22.51\tR: 24.16\tF1: 22.79\n",
      "\t\trouge-w:\tP: 12.67\tR:  6.19\tF1:  8.07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hypo=merged_df['summary'].tolist()\n",
    "refe1=merged_df['e_summarization'].tolist() #[reference]\n",
    "refe2=merged_df['a_summarization'].tolist() #[reference]\n",
    "refe3=merged_df['t5_summarization'].tolist() #[reference]\n",
    "refe6=merged_df['ss_summarization'].tolist() #[reference]\n",
    "\n",
    "print(\"Rogue for Extractive Summarization\")\n",
    "print_rogue_scores(hypo,refe1)    \n",
    "print(\"Rogue for Abstractive Summarization\")\n",
    "print_rogue_scores(hypo,refe2)   \n",
    "print(\"Rogue for T5 Summarization\")\n",
    "print_rogue_scores(hypo,refe3)        \n",
    "print(\"Rogue for SS Summarization\")\n",
    "print_rogue_scores(hypo,refe6) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75bf487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0d7cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:14:05.539500\n"
     ]
    }
   ],
   "source": [
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef9fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d977b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
